name: Tests

on:
  workflow_call:
    inputs:
      test_type:
        description: 'Type of tests to run (all, backend-unit, backend-integration, backend-e2e, frontend-unit, frontend-integration, frontend-e2e)'
        required: true
        type: string
      cache_dependencies:
        description: 'Whether to cache dependencies'
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  backend:
    if: inputs.test_type == 'all' || startsWith(inputs.test_type, 'backend-')
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
          POSTGRES_HOST_AUTH_METHOD: trust
        ports:
          - 5433:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d test_db"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 10
          --health-start-period 5s
    env:
      DATABASE_URL: postgresql://postgres:postgres@localhost:5433/test_db
      PROJECT_NAME: FastAPI
      POSTGRES_SERVER: localhost
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      FIRST_SUPERUSER: admin@example.com
      FIRST_SUPERUSER_PASSWORD: password
      PYTHONUNBUFFERED: "1"
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Create virtual environment and install dependencies
        working-directory: backend
        run: |
          echo "Creating virtual environment..."
          uv venv
          echo "Installing dependencies..."
          uv pip install -e ".[dev,test]"
          echo "Dependencies installed."

      - name: Check for backend test files
        working-directory: backend
        run: |
          echo "Checking for test files in each test directory..."

          # Check unit tests
          UNIT_TESTS=$(find tests/unit -name "test_*.py" | wc -l)
          echo "Found $UNIT_TESTS unit test files"
          if [ "$UNIT_TESTS" -eq 0 ]; then
            echo "::warning::No unit test files found in tests/unit directory"
          fi

          # Check integration tests
          INTEGRATION_TESTS=$(find tests/integration -name "test_*.py" | wc -l)
          echo "Found $INTEGRATION_TESTS integration test files"
          if [ "$INTEGRATION_TESTS" -eq 0 ]; then
            echo "::warning::No integration test files found in tests/integration directory"
          fi

          # Check API tests
          API_TESTS=$(find tests/api -name "test_*.py" | wc -l)
          echo "Found $API_TESTS API test files"
          if [ "$API_TESTS" -eq 0 ]; then
            echo "::warning::No API test files found in tests/api directory"
          fi

          # Check CRUD tests
          CRUD_TESTS=$(find tests/crud -name "test_*.py" | wc -l)
          echo "Found $CRUD_TESTS CRUD test files"
          if [ "$CRUD_TESTS" -eq 0 ]; then
            echo "::warning::No CRUD test files found in tests/crud directory"
          fi

          # Check e2e tests
          E2E_TESTS=$(find tests/e2e -name "test_*.py" 2>/dev/null | wc -l)
          echo "Found $E2E_TESTS e2e test files"
          if [ "$E2E_TESTS" -eq 0 ]; then
            echo "::warning::No e2e test files found in tests/e2e directory"
          fi

          # Ensure at least some tests exist
          TOTAL_TESTS=$((UNIT_TESTS + INTEGRATION_TESTS + API_TESTS + CRUD_TESTS + E2E_TESTS))
          if [ "$TOTAL_TESTS" -eq 0 ]; then
            echo "::error::No test files found in any test directory"
            exit 1
          fi

          echo "Test file check complete."

      - name: Run backend unit tests
        if: inputs.test_type == 'all' || inputs.test_type == 'backend-unit'
        id: unit_tests
        continue-on-error: true
        working-directory: backend
        run: |
          echo "Running backend unit tests..."
          uv run pytest tests/unit -v | tee unit_test_output.log

          # Check for failures
          if grep -q "FAILED" unit_test_output.log; then
            echo "::error::Unit tests failed"
            UNIT_FAILED=true
          else
            UNIT_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" unit_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in unit tests"
          fi

          # Save results for summary
          echo "unit_failed=$UNIT_FAILED" >> $GITHUB_OUTPUT
          echo "unit_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run backend integration tests
        if: inputs.test_type == 'all' || inputs.test_type == 'backend-integration'
        id: integration_tests
        continue-on-error: true
        working-directory: backend
        run: |
          echo "Running backend integration tests..."
          uv run pytest tests/integration -v | tee integration_test_output.log

          # Check for failures
          if grep -q "FAILED" integration_test_output.log; then
            echo "::error::Integration tests failed"
            INTEGRATION_FAILED=true
          else
            INTEGRATION_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" integration_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in integration tests"
          fi

          # Save results for summary
          echo "integration_failed=$INTEGRATION_FAILED" >> $GITHUB_OUTPUT
          echo "integration_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run backend e2e tests
        if: inputs.test_type == 'all' || inputs.test_type == 'backend-e2e'
        id: e2e_tests
        continue-on-error: true
        working-directory: backend
        run: |
          echo "Running backend e2e tests..."
          if [ -d "tests/e2e" ]; then
            uv run pytest tests/e2e -v | tee e2e_test_output.log

            # Check for failures
            if grep -q "FAILED" e2e_test_output.log; then
              echo "::error::E2E tests failed"
              E2E_FAILED=true
            else
              E2E_FAILED=false
            fi

            # Check for warnings
            WARNINGS=$(grep -c "warning" e2e_test_output.log || true)
            if [ "$WARNINGS" -gt 0 ]; then
              echo "::warning::$WARNINGS warnings found in e2e tests"
            fi

            # Save results for summary
            echo "e2e_failed=$E2E_FAILED" >> $GITHUB_OUTPUT
            echo "e2e_warnings=$WARNINGS" >> $GITHUB_OUTPUT
          else
            echo "::warning::No e2e test directory found"
            echo "e2e_failed=false" >> $GITHUB_OUTPUT
            echo "e2e_warnings=0" >> $GITHUB_OUTPUT
          fi

      - name: Run backend API tests
        if: inputs.test_type == 'all' || inputs.test_type == 'backend-unit' || inputs.test_type == 'backend-integration'
        id: api_tests
        continue-on-error: true
        working-directory: backend
        run: |
          echo "Running backend API tests..."
          if [ -d "tests/api" ]; then
            uv run pytest tests/api -v | tee api_test_output.log

            # Check for failures
            if grep -q "FAILED" api_test_output.log; then
              echo "::error::API tests failed"
              API_FAILED=true
            else
              API_FAILED=false
            fi

            # Check for warnings
            WARNINGS=$(grep -c "warning" api_test_output.log || true)
            if [ "$WARNINGS" -gt 0 ]; then
              echo "::warning::$WARNINGS warnings found in API tests"
            fi

            # Save results for summary
            echo "api_failed=$API_FAILED" >> $GITHUB_OUTPUT
            echo "api_warnings=$WARNINGS" >> $GITHUB_OUTPUT
          else
            echo "::warning::No API test directory found"
            echo "api_failed=false" >> $GITHUB_OUTPUT
            echo "api_warnings=0" >> $GITHUB_OUTPUT
          fi

      - name: Run backend CRUD tests
        if: inputs.test_type == 'all' || inputs.test_type == 'backend-unit' || inputs.test_type == 'backend-integration'
        id: crud_tests
        continue-on-error: true
        working-directory: backend
        run: |
          echo "Running backend CRUD tests..."
          if [ -d "tests/crud" ]; then
            uv run pytest tests/crud -v | tee crud_test_output.log

            # Check for failures
            if grep -q "FAILED" crud_test_output.log; then
              echo "::error::CRUD tests failed"
              CRUD_FAILED=true
            else
              CRUD_FAILED=false
            fi

            # Check for warnings
            WARNINGS=$(grep -c "warning" crud_test_output.log || true)
            if [ "$WARNINGS" -gt 0 ]; then
              echo "::warning::$WARNINGS warnings found in CRUD tests"
            fi

            # Save results for summary
            echo "crud_failed=$CRUD_FAILED" >> $GITHUB_OUTPUT
            echo "crud_warnings=$WARNINGS" >> $GITHUB_OUTPUT
          else
            echo "::warning::No CRUD test directory found"
            echo "crud_failed=false" >> $GITHUB_OUTPUT
            echo "crud_warnings=0" >> $GITHUB_OUTPUT
          fi

      - name: Backend test summary
        if: inputs.test_type == 'all' || startsWith(inputs.test_type, 'backend-')
        run: |
          echo "Backend Test Summary:"
          echo "===================="

          # Unit tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'backend-unit' }}" == "true" ]; then
            if [ "${{ steps.unit_tests.outputs.unit_failed }}" == "true" ]; then
              echo "❌ Unit tests: FAILED (with ${{ steps.unit_tests.outputs.unit_warnings }} warnings)"
            else
              echo "✅ Unit tests: PASSED (with ${{ steps.unit_tests.outputs.unit_warnings }} warnings)"
            fi
          else
            echo "⏭️ Unit tests: SKIPPED"
          fi

          # Integration tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'backend-integration' }}" == "true" ]; then
            if [ "${{ steps.integration_tests.outputs.integration_failed }}" == "true" ]; then
              echo "❌ Integration tests: FAILED (with ${{ steps.integration_tests.outputs.integration_warnings }} warnings)"
            else
              echo "✅ Integration tests: PASSED (with ${{ steps.integration_tests.outputs.integration_warnings }} warnings)"
            fi
          else
            echo "⏭️ Integration tests: SKIPPED"
          fi

          # E2E tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'backend-e2e' }}" == "true" ]; then
            if [ "${{ steps.e2e_tests.outputs.e2e_failed }}" == "true" ]; then
              echo "❌ E2E tests: FAILED (with ${{ steps.e2e_tests.outputs.e2e_warnings }} warnings)"
            else
              echo "✅ E2E tests: PASSED (with ${{ steps.e2e_tests.outputs.e2e_warnings }} warnings)"
            fi
          else
            echo "⏭️ E2E tests: SKIPPED"
          fi

          # API tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'backend-unit' || inputs.test_type == 'backend-integration' }}" == "true" ]; then
            if [ "${{ steps.api_tests.outputs.api_failed }}" == "true" ]; then
              echo "❌ API tests: FAILED (with ${{ steps.api_tests.outputs.api_warnings }} warnings)"
            else
              echo "✅ API tests: PASSED (with ${{ steps.api_tests.outputs.api_warnings }} warnings)"
            fi
          else
            echo "⏭️ API tests: SKIPPED"
          fi

          # CRUD tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'backend-unit' || inputs.test_type == 'backend-integration' }}" == "true" ]; then
            if [ "${{ steps.crud_tests.outputs.crud_failed }}" == "true" ]; then
              echo "❌ CRUD tests: FAILED (with ${{ steps.crud_tests.outputs.crud_warnings }} warnings)"
            else
              echo "✅ CRUD tests: PASSED (with ${{ steps.crud_tests.outputs.crud_warnings }} warnings)"
            fi
          else
            echo "⏭️ CRUD tests: SKIPPED"
          fi

          # Check if any tests failed
          if [ "${{ steps.unit_tests.outputs.unit_failed }}" == "true" ] || \
             [ "${{ steps.integration_tests.outputs.integration_failed }}" == "true" ] || \
             [ "${{ steps.e2e_tests.outputs.e2e_failed }}" == "true" ] || \
             [ "${{ steps.api_tests.outputs.api_failed }}" == "true" ] || \
             [ "${{ steps.crud_tests.outputs.crud_failed }}" == "true" ]; then
            echo "::error::One or more backend test suites failed"
            exit 1
          fi

  frontend:
    if: inputs.test_type == 'all' || startsWith(inputs.test_type, 'frontend-')
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
          POSTGRES_HOST_AUTH_METHOD: trust
        ports:
          - 5433:5432
        options: >-
          --health-cmd "pg_isready -U postgres -d test_db"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 10
          --health-start-period 5s
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 8
          run_install: false

      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install

      - name: Check for frontend test files
        run: |
          echo "Checking for frontend test files..."

          # Check unit tests
          UNIT_TESTS=$(find . -name "*.test.ts" -o -name "*.test.tsx" -o -name "*.spec.ts" -o -name "*.spec.tsx" | wc -l)
          echo "Found $UNIT_TESTS frontend test files"
          if [ "$UNIT_TESTS" -eq 0 ]; then
            echo "::warning::No frontend test files found"
          fi

          # Ensure at least some tests exist
          if [ "$UNIT_TESTS" -eq 0 ]; then
            echo "::error::No frontend test files found"
            exit 1
          fi

          echo "Frontend test file check complete."

      - name: Run frontend unit tests
        if: inputs.test_type == 'all' || inputs.test_type == 'frontend-unit'
        id: frontend_unit_tests
        continue-on-error: true
        run: |
          echo "Running frontend unit tests..."
          pnpm run test:unit | tee frontend_unit_test_output.log

          # Check for failures
          if grep -q "FAIL" frontend_unit_test_output.log; then
            echo "::error::Frontend unit tests failed"
            UNIT_FAILED=true
          else
            UNIT_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" frontend_unit_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in frontend unit tests"
          fi

          # Save results for summary
          echo "unit_failed=$UNIT_FAILED" >> $GITHUB_OUTPUT
          echo "unit_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run frontend integration tests
        if: inputs.test_type == 'all' || inputs.test_type == 'frontend-integration'
        id: frontend_integration_tests
        continue-on-error: true
        run: |
          echo "Running frontend integration tests..."
          if [ -f "package.json" ] && grep -q "test:integration" package.json; then
            pnpm run test:integration | tee frontend_integration_test_output.log

            # Check for failures
            if grep -q "FAIL" frontend_integration_test_output.log; then
              echo "::error::Frontend integration tests failed"
              INTEGRATION_FAILED=true
            else
              INTEGRATION_FAILED=false
            fi

            # Check for warnings
            WARNINGS=$(grep -c "warning" frontend_integration_test_output.log || true)
            if [ "$WARNINGS" -gt 0 ]; then
              echo "::warning::$WARNINGS warnings found in frontend integration tests"
            fi

            # Save results for summary
            echo "integration_failed=$INTEGRATION_FAILED" >> $GITHUB_OUTPUT
            echo "integration_warnings=$WARNINGS" >> $GITHUB_OUTPUT
          else
            echo "::warning::No integration test script found in package.json"
            echo "integration_failed=false" >> $GITHUB_OUTPUT
            echo "integration_warnings=0" >> $GITHUB_OUTPUT
          fi

      - name: Run frontend e2e tests
        if: inputs.test_type == 'all' || inputs.test_type == 'frontend-e2e'
        id: frontend_e2e_tests
        continue-on-error: true
        run: |
          echo "Running frontend e2e tests..."
          pnpm run test:e2e | tee frontend_e2e_test_output.log

          # Check for failures
          if grep -q "FAIL\|ERROR" frontend_e2e_test_output.log; then
            echo "::error::Frontend e2e tests failed"
            E2E_FAILED=true
          else
            E2E_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" frontend_e2e_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in frontend e2e tests"
          fi

          # Save results for summary
          echo "e2e_failed=$E2E_FAILED" >> $GITHUB_OUTPUT
          echo "e2e_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Frontend test summary
        if: inputs.test_type == 'all' || startsWith(inputs.test_type, 'frontend-')
        run: |
          echo "Frontend Test Summary:"
          echo "===================="

          # Unit tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'frontend-unit' }}" == "true" ]; then
            if [ "${{ steps.frontend_unit_tests.outputs.unit_failed }}" == "true" ]; then
              echo "❌ Unit tests: FAILED (with ${{ steps.frontend_unit_tests.outputs.unit_warnings }} warnings)"
            else
              echo "✅ Unit tests: PASSED (with ${{ steps.frontend_unit_tests.outputs.unit_warnings }} warnings)"
            fi
          else
            echo "⏭️ Unit tests: SKIPPED"
          fi

          # Integration tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'frontend-integration' }}" == "true" ]; then
            if [ "${{ steps.frontend_integration_tests.outputs.integration_failed }}" == "true" ]; then
              echo "❌ Integration tests: FAILED (with ${{ steps.frontend_integration_tests.outputs.integration_warnings }} warnings)"
            else
              echo "✅ Integration tests: PASSED (with ${{ steps.frontend_integration_tests.outputs.integration_warnings }} warnings)"
            fi
          else
            echo "⏭️ Integration tests: SKIPPED"
          fi

          # E2E tests
          if [ "${{ inputs.test_type == 'all' || inputs.test_type == 'frontend-e2e' }}" == "true" ]; then
            if [ "${{ steps.frontend_e2e_tests.outputs.e2e_failed }}" == "true" ]; then
              echo "❌ E2E tests: FAILED (with ${{ steps.frontend_e2e_tests.outputs.e2e_warnings }} warnings)"
            else
              echo "✅ E2E tests: PASSED (with ${{ steps.frontend_e2e_tests.outputs.e2e_warnings }} warnings)"
            fi
          else
            echo "⏭️ E2E tests: SKIPPED"
          fi

          # Check if any tests failed
          if [ "${{ steps.frontend_unit_tests.outputs.unit_failed }}" == "true" ] || \
             [ "${{ steps.frontend_integration_tests.outputs.integration_failed }}" == "true" ] || \
             [ "${{ steps.frontend_e2e_tests.outputs.e2e_failed }}" == "true" ]; then
            echo "::error::One or more frontend test suites failed"
            exit 1
          fi
