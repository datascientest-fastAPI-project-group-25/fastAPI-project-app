name: Local CI

on:
  push:
    branches: [ main, stg ]
  pull_request:
    branches: [ main, stg ]
  workflow_call:
    inputs:
      target:
        description: 'Target to test (backend, frontend, or all)'
        required: false
        type: string
        default: 'all'

permissions:
  contents: read

jobs:
  backend-lint:
    if: inputs.target == 'backend' || inputs.target == 'all' || inputs.target == ''
    runs-on: ubuntu-latest
    env:
      UV_SYSTEM_PYTHON: 1
    steps:
      - name: Checkout code
        if: env.ACT != 'true'
        uses: actions/checkout@v4

      - name: Check working directory (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local working directory..."
          ls -la
          echo "Working directory checked."

      - name: Setup Python
        if: env.ACT != 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Check Python (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local Python installation..."
          python --version
          echo "Python version checked."

      - name: Install uv
        if: env.ACT != 'true'
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Install uv (local)
        if: env.ACT == 'true'
        run: pip install uv

      - name: Install dependencies
        working-directory: backend
        run: uv pip install -e ".[dev,test]"

      - name: Run ruff linting
        working-directory: backend
        run: |
          uv run ruff check app
          uv run ruff format --check app

  frontend-lint:
    if: inputs.target == 'frontend' || inputs.target == 'all' || inputs.target == ''
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        if: env.ACT != 'true'
        uses: actions/checkout@v4

      - name: Check working directory (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local working directory..."
          ls -la
          echo "Working directory checked."

      - name: Setup Node.js
        if: env.ACT != 'true'
        uses: actions/setup-node@v4
        with:
          node-version: "18"

      - name: Check Node.js (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local Node.js installation..."
          node --version
          echo "Node.js version checked."

      - name: Install pnpm
        if: env.ACT != 'true'
        uses: pnpm/action-setup@v4
        with:
          version: 8
          run_install: false

      - name: Install pnpm (local)
        if: env.ACT == 'true'
        run: npm install -g pnpm

      - name: Get pnpm store directory
        if: env.ACT != 'true'
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        if: env.ACT != 'true'
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install

      - name: Run biome linting
        run: pnpm run lint

  backend-tests:
    if: inputs.target == 'backend' || inputs.target == 'all' || inputs.target == ''
    runs-on: ubuntu-latest
    env:
      UV_SYSTEM_PYTHON: 1
      DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
      PROJECT_NAME: FastAPI
      POSTGRES_SERVER: localhost
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      FIRST_SUPERUSER: admin@example.com
      FIRST_SUPERUSER_PASSWORD: password
      PYTHONUNBUFFERED: "1"
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
          POSTGRES_HOST_AUTH_METHOD: trust
        ports:
          - 5432:5432
        options: >
          --health-cmd "pg_isready -U postgres -d test_db"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 10
          --health-start-period 5s
    steps:
      - name: Checkout code
        if: env.ACT != 'true'
        uses: actions/checkout@v4

      - name: Check working directory (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local working directory..."
          ls -la
          echo "Working directory checked."

      - name: Setup Python
        if: env.ACT != 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Check Python (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local Python installation..."
          python --version
          echo "Python version checked."

      - name: Install uv
        if: env.ACT != 'true'
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Install uv (local)
        if: env.ACT == 'true'
        run: pip install uv

      - name: Install dependencies
        working-directory: backend
        run: uv pip install -e ".[dev,test]"

      - name: Check for backend test files
        working-directory: backend
        run: |
          echo "Checking for test files in each test directory..."

          # Check unit tests
          UNIT_TESTS=$(find tests/unit -name "test_*.py" | wc -l)
          echo "Found $UNIT_TESTS unit test files"
          if [ "$UNIT_TESTS" -eq 0 ]; then
            echo "::warning::No unit test files found in tests/unit directory"
          fi

          # Check integration tests
          INTEGRATION_TESTS=$(find tests/integration -name "test_*.py" | wc -l)
          echo "Found $INTEGRATION_TESTS integration test files"
          if [ "$INTEGRATION_TESTS" -eq 0 ]; then
            echo "::warning::No integration test files found in tests/integration directory"
          fi

          # Check API tests
          API_TESTS=$(find tests/api -name "test_*.py" | wc -l)
          echo "Found $API_TESTS API test files"
          if [ "$API_TESTS" -eq 0 ]; then
            echo "::warning::No API test files found in tests/api directory"
          fi

          # Check CRUD tests
          CRUD_TESTS=$(find tests/crud -name "test_*.py" | wc -l)
          echo "Found $CRUD_TESTS CRUD test files"
          if [ "$CRUD_TESTS" -eq 0 ]; then
            echo "::warning::No CRUD test files found in tests/crud directory"
          fi

          # Ensure at least some tests exist
          TOTAL_TESTS=$((UNIT_TESTS + INTEGRATION_TESTS + API_TESTS + CRUD_TESTS))
          if [ "$TOTAL_TESTS" -eq 0 ]; then
            echo "::error::No test files found in any test directory"
            exit 1
          fi

          echo "Test file check complete."

      - name: Run backend unit tests
        working-directory: backend
        id: unit_tests
        continue-on-error: true
        run: |
          echo "Running backend unit tests..."
          uv run pytest tests/unit -v | tee unit_test_output.log

          # Check for failures
          if grep -q "FAILED" unit_test_output.log; then
            echo "::error::Unit tests failed"
            UNIT_FAILED=true
          else
            UNIT_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" unit_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in unit tests"
          fi

          # Save results for summary
          echo "unit_failed=$UNIT_FAILED" >> $GITHUB_OUTPUT
          echo "unit_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run backend integration tests
        working-directory: backend
        id: integration_tests
        continue-on-error: true
        run: |
          echo "Running backend integration tests..."
          uv run pytest tests/integration -v | tee integration_test_output.log

          # Check for failures
          if grep -q "FAILED" integration_test_output.log; then
            echo "::error::Integration tests failed"
            INTEGRATION_FAILED=true
          else
            INTEGRATION_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" integration_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in integration tests"
          fi

          # Save results for summary
          echo "integration_failed=$INTEGRATION_FAILED" >> $GITHUB_OUTPUT
          echo "integration_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run backend API tests
        working-directory: backend
        id: api_tests
        continue-on-error: true
        run: |
          echo "Running backend API tests..."
          uv run pytest tests/api -v | tee api_test_output.log

          # Check for failures
          if grep -q "FAILED" api_test_output.log; then
            echo "::error::API tests failed"
            API_FAILED=true
          else
            API_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" api_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in API tests"
          fi

          # Save results for summary
          echo "api_failed=$API_FAILED" >> $GITHUB_OUTPUT
          echo "api_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run backend CRUD tests
        working-directory: backend
        id: crud_tests
        continue-on-error: true
        run: |
          echo "Running backend CRUD tests..."
          uv run pytest tests/crud -v | tee crud_test_output.log

          # Check for failures
          if grep -q "FAILED" crud_test_output.log; then
            echo "::error::CRUD tests failed"
            CRUD_FAILED=true
          else
            CRUD_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" crud_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in CRUD tests"
          fi

          # Save results for summary
          echo "crud_failed=$CRUD_FAILED" >> $GITHUB_OUTPUT
          echo "crud_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Backend test summary
        working-directory: backend
        run: |
          echo "Backend Test Summary:"
          echo "===================="

          # Unit tests
          if [ "${{ steps.unit_tests.outputs.unit_failed }}" == "true" ]; then
            echo "❌ Unit tests: FAILED (with ${{ steps.unit_tests.outputs.unit_warnings }} warnings)"
          else
            echo "✅ Unit tests: PASSED (with ${{ steps.unit_tests.outputs.unit_warnings }} warnings)"
          fi

          # Integration tests
          if [ "${{ steps.integration_tests.outputs.integration_failed }}" == "true" ]; then
            echo "❌ Integration tests: FAILED (with ${{ steps.integration_tests.outputs.integration_warnings }} warnings)"
          else
            echo "✅ Integration tests: PASSED (with ${{ steps.integration_tests.outputs.integration_warnings }} warnings)"
          fi

          # API tests
          if [ "${{ steps.api_tests.outputs.api_failed }}" == "true" ]; then
            echo "❌ API tests: FAILED (with ${{ steps.api_tests.outputs.api_warnings }} warnings)"
          else
            echo "✅ API tests: PASSED (with ${{ steps.api_tests.outputs.api_warnings }} warnings)"
          fi

          # CRUD tests
          if [ "${{ steps.crud_tests.outputs.crud_failed }}" == "true" ]; then
            echo "❌ CRUD tests: FAILED (with ${{ steps.crud_tests.outputs.crud_warnings }} warnings)"
          else
            echo "✅ CRUD tests: PASSED (with ${{ steps.crud_tests.outputs.crud_warnings }} warnings)"
          fi

          # Check if any tests failed
          if [ "${{ steps.unit_tests.outputs.unit_failed }}" == "true" ] || \
             [ "${{ steps.integration_tests.outputs.integration_failed }}" == "true" ] || \
             [ "${{ steps.api_tests.outputs.api_failed }}" == "true" ] || \
             [ "${{ steps.crud_tests.outputs.crud_failed }}" == "true" ]; then
            echo "::error::One or more backend test suites failed"
            exit 1
          fi

  frontend-tests:
    if: inputs.target == 'frontend' || inputs.target == 'all' || inputs.target == ''
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        if: env.ACT != 'true'
        uses: actions/checkout@v4

      - name: Check working directory (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local working directory..."
          ls -la
          echo "Working directory checked."

      - name: Setup Node.js
        if: env.ACT != 'true'
        uses: actions/setup-node@v4
        with:
          node-version: "18"

      - name: Check Node.js (local)
        if: env.ACT == 'true'
        run: |
          echo "Using local Node.js installation..."
          node --version
          echo "Node.js version checked."

      - name: Install pnpm
        if: env.ACT != 'true'
        uses: pnpm/action-setup@v4
        with:
          version: 8
          run_install: false

      - name: Install pnpm (local)
        if: env.ACT == 'true'
        run: npm install -g pnpm

      - name: Get pnpm store directory
        if: env.ACT != 'true'
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        if: env.ACT != 'true'
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install

      - name: Check for frontend test files
        run: |
          echo "Checking for frontend test files..."

          # Check unit tests
          UNIT_TESTS=$(find frontend/tests -name "*.test.ts" -o -name "*.test.tsx" -o -name "*.spec.ts" -o -name "*.spec.tsx" | wc -l)
          echo "Found $UNIT_TESTS frontend unit test files"
          if [ "$UNIT_TESTS" -eq 0 ]; then
            echo "::warning::No frontend unit test files found"
          fi

          # Check e2e tests
          E2E_TESTS=$(find frontend/tests -name "*.spec.ts" | wc -l)
          echo "Found $E2E_TESTS frontend e2e test files"
          if [ "$E2E_TESTS" -eq 0 ]; then
            echo "::warning::No frontend e2e test files found"
          fi

          # Ensure at least some tests exist
          TOTAL_TESTS=$((UNIT_TESTS + E2E_TESTS))
          if [ "$TOTAL_TESTS" -eq 0 ]; then
            echo "::error::No frontend test files found"
            exit 1
          fi

          echo "Frontend test file check complete."

      - name: Run frontend unit tests
        id: frontend_unit_tests
        continue-on-error: true
        run: |
          echo "Running frontend unit tests..."
          pnpm run test:unit | tee frontend_unit_test_output.log

          # Check for failures
          if grep -q "FAIL" frontend_unit_test_output.log; then
            echo "::error::Frontend unit tests failed"
            UNIT_FAILED=true
          else
            UNIT_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" frontend_unit_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in frontend unit tests"
          fi

          # Save results for summary
          echo "unit_failed=$UNIT_FAILED" >> $GITHUB_OUTPUT
          echo "unit_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Run frontend e2e tests
        id: frontend_e2e_tests
        continue-on-error: true
        run: |
          echo "Running frontend e2e tests..."
          pnpm run test:e2e | tee frontend_e2e_test_output.log

          # Check for failures
          if grep -q "FAIL\|ERROR" frontend_e2e_test_output.log; then
            echo "::error::Frontend e2e tests failed"
            E2E_FAILED=true
          else
            E2E_FAILED=false
          fi

          # Check for warnings
          WARNINGS=$(grep -c "warning" frontend_e2e_test_output.log || true)
          if [ "$WARNINGS" -gt 0 ]; then
            echo "::warning::$WARNINGS warnings found in frontend e2e tests"
          fi

          # Save results for summary
          echo "e2e_failed=$E2E_FAILED" >> $GITHUB_OUTPUT
          echo "e2e_warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Frontend test summary
        run: |
          echo "Frontend Test Summary:"
          echo "===================="

          # Unit tests
          if [ "${{ steps.frontend_unit_tests.outputs.unit_failed }}" == "true" ]; then
            echo "❌ Unit tests: FAILED (with ${{ steps.frontend_unit_tests.outputs.unit_warnings }} warnings)"
          else
            echo "✅ Unit tests: PASSED (with ${{ steps.frontend_unit_tests.outputs.unit_warnings }} warnings)"
          fi

          # E2E tests
          if [ "${{ steps.frontend_e2e_tests.outputs.e2e_failed }}" == "true" ]; then
            echo "❌ E2E tests: FAILED (with ${{ steps.frontend_e2e_tests.outputs.e2e_warnings }} warnings)"
          else
            echo "✅ E2E tests: PASSED (with ${{ steps.frontend_e2e_tests.outputs.e2e_warnings }} warnings)"
          fi

          # Check if any tests failed
          if [ "${{ steps.frontend_unit_tests.outputs.unit_failed }}" == "true" ] || \
             [ "${{ steps.frontend_e2e_tests.outputs.e2e_failed }}" == "true" ]; then
            echo "::error::One or more frontend test suites failed"
            exit 1
          fi
